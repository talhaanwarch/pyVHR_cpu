{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"collapsed_sections":["LDtGQze9r-_F","GnKKDdQ_ZhGO","YYuRKRuiv12r"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["---\n","# **PyVHR demo (deep)**\n","---"],"metadata":{"id":"LDtGQze9r-_F"}},{"cell_type":"code","metadata":{"id":"nFP37oIXuKQN"},"source":["# -- MAIN IMPORT\n","\n","import pyVHR as vhr\n","import numpy as np\n","\n","# Plotting: set 'colab' for Google Colaboratory, 'notebook' otherwise\n","vhr.plot.VisualizeParams.renderer = 'colab'  # or 'notebook'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YYKTCUkf7Y6l"},"source":["# -- LOAD A DATASET\n","\n","dataset_name = 'PURE'                   # the name of the python class handling it \n","video_DIR = '/var/datasets/VHR1/PURE/'  # dir containing videos\n","BVP_DIR = '/var/datasets/VHR1/PURE/'    # dir containing BVPs GT\n","\n","dataset = vhr.datasets.datasetFactory(dataset_name, videodataDIR=video_DIR, BVPdataDIR=BVP_DIR)\n","allvideo = dataset.videoFilenames\n","\n","# print the list of video names with the progressive index (idx)\n","for v in range(len(allvideo)):\n","  print(v, allvideo[v])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AKz1w2i48u-Z"},"source":["# -- PARAMETER SETTING\n","\n","wsize = 6           # seconds of video processed (with overlapping) for each estimate \n","video_idx = 50      # index of the video to be processed\n","fname = dataset.getSigFilename(video_idx)\n","sigGT = dataset.readSigfile(fname)\n","bpmGT, timesGT = sigGT.getBPM(wsize)\n","videoFileName = dataset.getVideoFilename(video_idx)\n","print('Video processed name: ', videoFileName)\n","fps = vhr.extraction.get_fps(videoFileName)\n","print('Video frame rate:     ',fps)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bv3FNU0kxLI8"},"source":["# -- DISPLAY VIDEO FRAMES\n","\n","vhr.plot.display_video(videoFileName)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# extract raw frames\n","sp = vhr.extraction.sig_processing.SignalProcessing()\n","frames = sp.extract_raw(videoFileName)\n","print('Frames shape:', frames.shape)"],"metadata":{"id":"u887ao15vrZZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# MTTS-CAN"],"metadata":{"id":"GnKKDdQ_ZhGO"}},{"cell_type":"markdown","source":["**DeepPhys: Video-Based Physiological Measurement Using Convolutional Attention Networks**\n","\n","*Weixuan Chen and Daniel McDuff*\n","\n","papers: \n","* [DeepPhys: Video-Based Physiological Measurement Using Convolutional Attention Networks](https://web.media.mit.edu/~cvx/docs/18.Chen-etal-ECCV.pdf), \n","* [Multi-Task Temporal Shift Attention Networks for On-Device Contactless Vitals Measurement\n","](https://papers.nips.cc/paper/2020/file/e1228be46de6a0234ac22ded31417bc7-Paper.pdf)\n"],"metadata":{"id":"dd9-878FZc88"}},{"cell_type":"code","source":["# apply MTTS_CAN model\n","bvp_pred = vhr.deepRPPG.MTTS_CAN_deep(frames, fps, verb=1)\n","bvps = vhr.BPM.BVPsignal(bvp_pred, fps) # BVP object\n","vhr.plot.visualize_BVPs([bvps.data], 0)"],"metadata":{"id":"e2WR2MU6L-y1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## -- analysis\n","from pyVHR.utils.errors import getErrors, printErrors, displayErrors, BVP_windowing\n","\n","# BVP windowing & BPM estimate\n","bvp_win, timesES = BVP_windowing(bvp_pred, wsize, fps, stride=1)\n","bpmES = vhr.BPM.BVP_to_BPM(bvp_win, fps) \n","\n","# compute and print errors\n","RMSE, MAE, MAX, PCC, CCC, SNR = vhr.utils.getErrors(bvp_win, fps, bpmES, bpmGT, timesES, timesGT)\n","vhr.utils.printErrors(RMSE, MAE, MAX, PCC, CCC, SNR)\n","displayErrors(bpmES, bpmGT, timesES, timesGT)"],"metadata":{"id":"5nVCmksezBGq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# HR-CNN"],"metadata":{"id":"YYuRKRuiv12r"}},{"cell_type":"markdown","source":["**Visual Heart Rate Estimation with Convolutional Neural Network**\n","\n","Spetlik, R., Franc, V., Cech, J. and Matas, J. (2018) \n","\n","See http://cmp.felk.cvut.cz/~spetlrad/ecg-fitness/ for the original paper and the ECG-Fitness dataset.\n","\n"],"metadata":{"id":"ZVFehITSsg0X"}},{"cell_type":"code","source":["# apply HR_CNN model\n","bvp_pred = vhr.deepRPPG.HR_CNN_bvp_pred(frames)\n","bvps = vhr.BPM.BVPsignal(bvp_pred, fps) # BVP object\n","vhr.plot.visualize_BVPs([bvps.data], 0)"],"metadata":{"id":"IedFvih0udEG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## -- analysis\n","from pyVHR.utils.errors import getErrors, printErrors, displayErrors, BVP_windowing\n","\n","# BVP windowing & BPM estimate\n","bvp_win, timesES = BVP_windowing(bvp_pred, wsize, fps, stride=1)\n","bpmES = vhr.BPM.BVP_to_BPM(bvp_win, fps) \n","\n","# compute and print errors\n","RMSE, MAE, MAX, PCC, CCC, SNR = vhr.utils.getErrors(bvp_win, fps, bpmES, bpmGT, timesES, timesGT)\n","vhr.utils.printErrors(RMSE, MAE, MAX, PCC, CCC, SNR)\n","displayErrors(bpmES, bpmGT, timesES, timesGT)"],"metadata":{"id":"_mjY5xl8ukUZ"},"execution_count":null,"outputs":[]}]}